import torch
import torch.nn as nn
import numpy as np

from schnetpack.nn.base import Dense
from schnetpack import Properties
from schnetpack.nn.cfconv import CFConv

### Added by Justin:
from schnetpack.nn.attention import EgoAttention
from schnetpack.nn.act import AdaptiveComputationTime

from schnetpack.nn.cutoff import CosineCutoff
###from schnetpack.nn.acsf import GaussianSmearing
from schnetpack.nn.acsf import LogNormalSmearing
from schnetpack.nn.neighbors import AtomDistances
###from schnetpack.nn.activations import shifted_softplus
from schnetpack.nn.activations import swish,shifted_softplus


class Transition(nn.Module):
    ### Added by Justin
    r"""Transition block for updating atomic embeddings.

    Args:
        n_atom_basis (int): number of features to describe atomic environments.
        n_hidden (int): number of hidden units in the FFMLP. Usually larger than n_atom_basis (recommend: 4*n_atom_basis).
        normalize_filter (bool, optional): if True, divide aggregated filter by number
            of neighbors over which convolution is applied.

    """

    def __init__(
        self,
        n_atom_basis,
        n_hidden,
        activation=None,
        dropout_rate=0,
        ###if_layer_norm=True,
    ):
        super(Transition, self).__init__()

        # filter block used in interaction block
        ###self.layer_norm_in = nn.LayerNorm([n_atom_basis]) ###(input.size()[-1])
        self.layer_norm_out = nn.LayerNorm([n_atom_basis]) ###(input.size()[-1])
        
        self.transition_network = nn.Sequential(
            Dense(n_atom_basis, n_hidden, activation=activation),
            nn.Dropout(dropout_rate),
            Dense(n_hidden, n_atom_basis, activation=None),
        )
                                                       

    def forward(self, x, v):
        """Compute interaction output.

        Args:
            x (torch.Tensor): input representation/embedding of atomic environments
                with (N_b, N_a, n_atom_basis) shape.
            r_ij (torch.Tensor): interatomic distances of (N_b, N_a, N_nbh) shape.
            neighbors (torch.Tensor): indices of neighbors of (N_b, N_a, N_nbh) shape.
            neighbor_mask (torch.Tensor): mask to filter out non-existing neighbors
                introduced via padding.
            f_ij (torch.Tensor, optional): expanded interatomic distances in a basis.
                If None, r_ij.unsqueeze(-1) is used.

        Returns:
            torch.Tensor: block output with (N_b, N_a, n_atom_basis) shape.

        """
        # continuous-filter convolution interaction block followed by Dense layer
        x = x + v
        x = self.layer_norm_out(x)
        x_t = self.transition_network(x)
        x = x + x_t
        
        ###x = self.layer_norm_out(x_out)

        return x
    

class SchNetInteraction(nn.Module):
    r"""SchNet interaction block for modeling interactions of atomistic systems.

    Args:
        n_atom_basis (int): number of features to describe atomic environments.
        n_spatial_basis (int): number of input features of filter-generating networks.
        ###n_filters (int): number of Value vectors in Multi_Head_Attention. Default: = n_atom_basis.
        cutoff (float): cutoff radius.
        cutoff_network (nn.Module, optional): cutoff layer.
        normalize_filter (bool, optional): if True, divide aggregated filter by number
            of neighbors over which convolution is applied.

    """

    def __init__(
        self,
        n_atom_basis,
        n_spatial_basis,
        n_heads,
        n_hidden,

        cutoff,        
        cutoff_network=CosineCutoff,
        normalize_filter=False,
        activation=None,
        apply_transition_function=True,
        dropout_rate=0,
    ):
        super(SchNetInteraction, self).__init__()
#         # filter block used in interaction block
#         self.filter_network = nn.Sequential(
#             Dense(n_spatial_basis, n_atom_basis, activation=swish),
#             Dense(n_atom_basis, n_atom_basis),
#         )

        # filter block used in interaction block
        ###self.filter_network = Dense(n_spatial_basis, n_atom_basis, bias=False, activation=None) 
        self.filter_network = Dense(n_spatial_basis, n_atom_basis, bias=True, activation=None) 
        
#         self.filter_network = nn.Sequential(
#             Dense(n_spatial_basis, n_hidden, activation=swish),
#             Dense(n_hidden, n_atom_basis),
#         )
    
        # cutoff layer used in interaction block
        self.cutoff_network = cutoff_network(cutoff)
        
        # Perform Ego-Attention:
        self.attention_network = EgoAttention(n_atom_basis, n_heads=n_heads, normalize_filter=normalize_filter)
        
        # interaction block
        self.cfconv = CFConv(
            n_atom_basis,
            ###n_filters,
            n_atom_basis,
            self.filter_network,
            ### Added by Justin:
            self.attention_network,
            cutoff_network=self.cutoff_network,
            activation=activation,
            normalize_filter=normalize_filter,
        )
        #### dense layer
        ###self.dense = Dense(n_atom_basis, n_atom_basis, bias=True, activation=None)
        
        # Transition function:
        self.apply_transition_function = apply_transition_function
        self.transition = Transition(n_atom_basis=n_atom_basis,n_hidden=n_hidden, activation=activation, dropout_rate=dropout_rate )        
        

    def forward(self, e, x, r_ij, neighbors, neighbor_mask, f_ij=None):
        """Compute interaction output.

        Args:
            x (torch.Tensor): input representation/embedding of atomic environments
                with (N_b, N_a, n_atom_basis) shape.
            r_ij (torch.Tensor): interatomic distances of (N_b, N_a, N_nbh) shape.
            neighbors (torch.Tensor): indices of neighbors of (N_b, N_a, N_nbh) shape.
            neighbor_mask (torch.Tensor): mask to filter out non-existing neighbors
                introduced via padding.
            f_ij (torch.Tensor, optional): expanded interatomic distances in a basis.
                If None, r_ij.unsqueeze(-1) is used.

        Returns:
            torch.Tensor: block output with (N_b, N_a, n_atom_basis) shape.

        """
        # continuous-filter convolution interaction block followed by Dense layer
        v = self.cfconv(e, x, r_ij, neighbors, neighbor_mask, f_ij)

        if self.apply_transition_function:
            x = self.transition(x, v) 
        else:
            x = x + v
        
        return x  ### v
    

# class SchNetInteraction(nn.Module):
#     r"""SchNet interaction block for modeling interactions of atomistic systems.

#     Args:
#         n_atom_basis (int): number of features to describe atomic environments.
#         n_spatial_basis (int): number of input features of filter-generating networks.
#         n_filters (int): number of filters used in continuous-filter convolution.
#         cutoff (float): cutoff radius.
#         cutoff_network (nn.Module, optional): cutoff layer.
#         normalize_filter (bool, optional): if True, divide aggregated filter by number
#             of neighbors over which convolution is applied.

#     """

#     def __init__(
#         self,
#         n_atom_basis,
#         n_spatial_basis,
#         n_filters,
#         cutoff,
#         cutoff_network=CosineCutoff,
#         normalize_filter=False,
#     ):
#         super(SchNetInteraction, self).__init__()
#         # filter block used in interaction block
#         self.filter_network = nn.Sequential(
#             Dense(n_spatial_basis, n_filters, activation=shifted_softplus),
#             Dense(n_filters, n_filters),
#         )
#         # cutoff layer used in interaction block
#         self.cutoff_network = cutoff_network(cutoff)
#         # interaction block
#         self.cfconv = CFConv(
#             n_atom_basis,
#             n_filters,
#             n_atom_basis,
#             self.filter_network,
#             cutoff_network=self.cutoff_network,
#             activation=shifted_softplus,
#             normalize_filter=normalize_filter,
#         )
#         # dense layer
#         self.dense = Dense(n_atom_basis, n_atom_basis, bias=True, activation=None)

#     def forward(self, x, r_ij, neighbors, neighbor_mask, f_ij=None):
#         """Compute interaction output.

#         Args:
#             x (torch.Tensor): input representation/embedding of atomic environments
#                 with (N_b, N_a, n_atom_basis) shape.
#             r_ij (torch.Tensor): interatomic distances of (N_b, N_a, N_nbh) shape.
#             neighbors (torch.Tensor): indices of neighbors of (N_b, N_a, N_nbh) shape.
#             neighbor_mask (torch.Tensor): mask to filter out non-existing neighbors
#                 introduced via padding.
#             f_ij (torch.Tensor, optional): expanded interatomic distances in a basis.
#                 If None, r_ij.unsqueeze(-1) is used.

#         Returns:
#             torch.Tensor: block output with (N_b, N_a, n_atom_basis) shape.

#         """
#         # continuous-filter convolution interaction block followed by Dense layer
#         v = self.cfconv(x, r_ij, neighbors, neighbor_mask, f_ij)
#         v = self.dense(v)
#         return v


class SchNet(nn.Module):
    """SchNet architecture for learning representations of atomistic systems.

    Args:
        n_atom_basis (int, optional): number of features to describe atomic environments.
            This determines the size of each embedding vector; i.e. embeddings_dim.
        n_filters (int, optional): number of filters used in continuous-filter convolution
        n_interactions (int, optional): number of interaction blocks.
        cutoff (float, optional): cutoff radius.
        n_gaussians (int, optional): number of Gaussian functions used to expand
            atomic distances.
        normalize_filter (bool, optional): if True, divide aggregated filter by number
            of neighbors over which convolution is applied.
        coupled_interactions (bool, optional): if True, share the weights across
            interaction blocks and filter-generating networks.
        return_intermediate (bool, optional): if True, `forward` method also returns
            intermediate atomic representations after each interaction block is applied.
        max_z (int, optional): maximum nuclear charge allowed in database. This
            determines the size of the dictionary of embedding; i.e. num_embeddings.
        cutoff_network (nn.Module, optional): cutoff layer.
        trainable_gaussians (bool, optional): If True, widths and offset of Gaussian
            functions are adjusted during training process.
        distance_expansion (nn.Module, optional): layer for expanding interatomic
            distances in a basis.
        charged_systems (bool, optional):

    References:
    .. [#schnet1] Schütt, Arbabzadah, Chmiela, Müller, Tkatchenko:
       Quantum-chemical insights from deep tensor neural networks.
       Nature Communications, 8, 13890. 2017.
    .. [#schnet_transfer] Schütt, Kindermans, Sauceda, Chmiela, Tkatchenko, Müller:
       SchNet: A continuous-filter convolutional neural network for modeling quantum
       interactions.
       In Advances in Neural Information Processing Systems, pp. 992-1002. 2017.
    .. [#schnet3] Schütt, Sauceda, Kindermans, Tkatchenko, Müller:
       SchNet - a deep learning architecture for molceules and materials.
       The Journal of Chemical Physics 148 (24), 241722. 2018.

    """

    def __init__(
        self,
        n_atom_basis=128,
        n_hidden=256,
        n_interactions=3,
        cutoff=5.0, ### 5.0,
        n_gaussians=32, ### 25
        n_heads=8,
        activation=swish,
        apply_transition_function=True,
        use_act=True,
        dropout_rate=0.01,
        normalize_filter=False,
        coupled_interactions=False,
        return_intermediate=False,
        max_z=100,
        cutoff_network=CosineCutoff,
        trainable_gaussians=False,
        distance_expansion=None,
        charged_systems=False,
    ):
        super(SchNet, self).__init__()

        self.n_atom_basis = n_atom_basis
        # make a lookup table to store embeddings for each element (up to atomic
        # number max_z) each of which is a vector of size n_atom_basis
        self.embedding = nn.Embedding(max_z, n_atom_basis, padding_idx=0)

        # layer for computing interatomic distances
        self.distances = AtomDistances()

        # layer for expanding interatomic distances in a basis
        if distance_expansion is None:
            ###self.distance_expansion = GaussianSmearing(
            ###    0.0, cutoff, n_gaussians, trainable=trainable_gaussians
            ###)
            ### Added by Justin:
            self.distance_expansion = LogNormalSmearing(
                np.log(0.1), np.log(cutoff), n_gaussians, trainable=trainable_gaussians
            )
        else:
            self.distance_expansion = distance_expansion

        # block for computing interaction
        if coupled_interactions:
            # use the same SchNetInteraction instance (hence the same weights)
            self.interactions = nn.ModuleList(
                [
                    SchNetInteraction(
                        n_atom_basis=n_atom_basis,
                        n_spatial_basis=n_gaussians,
                        n_heads=n_heads,
                        n_hidden=n_hidden,
                        cutoff_network=cutoff_network,
                        cutoff=cutoff,
                        normalize_filter=normalize_filter,
                        activation=activation,
                        apply_transition_function=apply_transition_function,
                        dropout_rate=dropout_rate,
                    )
                ]
                * n_interactions
            )
        else:
            # use one SchNetInteraction instance for each interaction
            self.interactions = nn.ModuleList(
                [
                    SchNetInteraction(
                        n_atom_basis=n_atom_basis,
                        n_spatial_basis=n_gaussians,
                        n_heads=n_heads,
                        n_hidden=n_hidden,
                        cutoff_network=cutoff_network,
                        cutoff=cutoff,
                        normalize_filter=normalize_filter,
                        activation=activation,
                        apply_transition_function=apply_transition_function,
                        dropout_rate=dropout_rate,
                    )
                    for _ in range(n_interactions)
                ]
            )
        
        ### Adaptive Computation:
        self.act_function = AdaptiveComputationTime(
            act_steps=n_interactions,
            n_atom_basis=n_atom_basis,
            n_hidden=n_hidden,
            activation=activation,
            dropout_rate=dropout_rate,
        )
        
        self.use_act = use_act
        
        
        # set attributes
        self.return_intermediate = return_intermediate
        self.charged_systems = charged_systems
        if charged_systems:
            self.charge = nn.Parameter(torch.Tensor(1, n_atom_basis))
            self.charge.data.normal_(0, 1.0 / n_atom_basis ** 0.5)

    def forward(self, inputs):
        """Compute atomic representations/embeddings.

        Args:
            inputs (dict of torch.Tensor): SchNetPack dictionary of input tensors.

        Returns:
            torch.Tensor: atom-wise representation.
            list of torch.Tensor: intermediate atom-wise representations, if
            return_intermediate=True was used.

        """
        # get tensors from input dictionary
        atomic_numbers = inputs[Properties.Z]
        positions = inputs[Properties.R]
        cell = inputs[Properties.cell]
        cell_offset = inputs[Properties.cell_offset]
        neighbors = inputs[Properties.neighbors]
        neighbor_mask = inputs[Properties.neighbor_mask]
        atom_mask = inputs[Properties.atom_mask]

        # get atom embeddings for the input atomic numbers
        e = self.embedding(atomic_numbers)
        x = e

        if False and self.charged_systems and Properties.charge in inputs.keys():
            n_atoms = torch.sum(atom_mask, dim=1, keepdim=True)
            charge = inputs[Properties.charge] / n_atoms  # B
            charge = charge[:, None] * self.charge  # B x F
            x = x + charge

        # compute interatomic distance of every atom to its neighbors
        r_ij = self.distances(
            positions, neighbors, cell, cell_offset, neighbor_mask=neighbor_mask
        )
        # expand interatomic distances (for example, Gaussian smearing)
        f_ij = self.distance_expansion(r_ij)
        
        # store intermediate representations
        
        if self.return_intermediate:
            xs = [x]
        
        # compute interaction block to update atomic embeddings
        x_list = []
        for i_layer, interaction in enumerate(self.interactions):
            x = interaction(e, x, r_ij, neighbors, neighbor_mask, f_ij=f_ij)            
            x_list.append(x)
            
            if self.return_intermediate:
                xs.append(x)
                
        if self.use_act:
            x = self.act_function(x_list)
                        
        if self.return_intermediate:
            return x, xs
        return x
